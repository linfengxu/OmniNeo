{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a3b101b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading data...\n",
      "Train samples: 6267\n",
      "Val samples: 1567\n",
      "\n",
      "============================================================\n",
      "Training CNN\n",
      "============================================================\n",
      "\n",
      "Model parameters: 14,594,498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 (15.0s)\n",
      "  Train - Loss: 0.5951, Acc: 0.6675\n",
      "  Val   - Loss: 0.5015, Acc: 0.7371, AUC: 0.8276, AUPR: 0.7370\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 (14.5s)\n",
      "  Train - Loss: 0.5022, Acc: 0.7421\n",
      "  Val   - Loss: 0.4680, Acc: 0.7913, AUC: 0.8592, AUPR: 0.7825\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 (14.6s)\n",
      "  Train - Loss: 0.4874, Acc: 0.7581\n",
      "  Val   - Loss: 0.4571, Acc: 0.7671, AUC: 0.8619, AUPR: 0.7886\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 (14.4s)\n",
      "  Train - Loss: 0.4816, Acc: 0.7591\n",
      "  Val   - Loss: 0.4500, Acc: 0.7735, AUC: 0.8683, AUPR: 0.7989\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 (13.6s)\n",
      "  Train - Loss: 0.4679, Acc: 0.7769\n",
      "  Val   - Loss: 0.4517, Acc: 0.7658, AUC: 0.8672, AUPR: 0.7992\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 (13.8s)\n",
      "  Train - Loss: 0.4665, Acc: 0.7728\n",
      "  Val   - Loss: 0.4377, Acc: 0.8009, AUC: 0.8720, AUPR: 0.8051\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 (14.4s)\n",
      "  Train - Loss: 0.4573, Acc: 0.7804\n",
      "  Val   - Loss: 0.4427, Acc: 0.7728, AUC: 0.8736, AUPR: 0.8073\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 (14.7s)\n",
      "  Train - Loss: 0.4576, Acc: 0.7792\n",
      "  Val   - Loss: 0.4398, Acc: 0.7958, AUC: 0.8776, AUPR: 0.8140\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 (14.0s)\n",
      "  Train - Loss: 0.4520, Acc: 0.7769\n",
      "  Val   - Loss: 0.4273, Acc: 0.7907, AUC: 0.8790, AUPR: 0.8151\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 (13.4s)\n",
      "  Train - Loss: 0.4405, Acc: 0.7891\n",
      "  Val   - Loss: 0.4188, Acc: 0.7958, AUC: 0.8808, AUPR: 0.8196\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 (13.4s)\n",
      "  Train - Loss: 0.4356, Acc: 0.7908\n",
      "  Val   - Loss: 0.4149, Acc: 0.8105, AUC: 0.8841, AUPR: 0.8241\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 (16.3s)\n",
      "  Train - Loss: 0.4401, Acc: 0.7916\n",
      "  Val   - Loss: 0.4158, Acc: 0.7990, AUC: 0.8845, AUPR: 0.8258\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 (18.1s)\n",
      "  Train - Loss: 0.4309, Acc: 0.7911\n",
      "  Val   - Loss: 0.4157, Acc: 0.8073, AUC: 0.8847, AUPR: 0.8265\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 (20.2s)\n",
      "  Train - Loss: 0.4336, Acc: 0.7975\n",
      "  Val   - Loss: 0.4078, Acc: 0.8079, AUC: 0.8875, AUPR: 0.8291\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 (19.9s)\n",
      "  Train - Loss: 0.4213, Acc: 0.7996\n",
      "  Val   - Loss: 0.4071, Acc: 0.8130, AUC: 0.8872, AUPR: 0.8303\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 (19.8s)\n",
      "  Train - Loss: 0.4236, Acc: 0.7961\n",
      "  Val   - Loss: 0.4074, Acc: 0.8117, AUC: 0.8863, AUPR: 0.8295\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 (21.2s)\n",
      "  Train - Loss: 0.4242, Acc: 0.7977\n",
      "  Val   - Loss: 0.4106, Acc: 0.7971, AUC: 0.8826, AUPR: 0.8255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 (18.7s)\n",
      "  Train - Loss: 0.4233, Acc: 0.7958\n",
      "  Val   - Loss: 0.4005, Acc: 0.8188, AUC: 0.8897, AUPR: 0.8347\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 (19.0s)\n",
      "  Train - Loss: 0.4099, Acc: 0.8028\n",
      "  Val   - Loss: 0.3984, Acc: 0.8124, AUC: 0.8906, AUPR: 0.8370\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 (20.6s)\n",
      "  Train - Loss: 0.4111, Acc: 0.8064\n",
      "  Val   - Loss: 0.3956, Acc: 0.8175, AUC: 0.8919, AUPR: 0.8382\n",
      "  [*] Best model saved!\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training BiLSTM\n",
      "============================================================\n",
      "\n",
      "Model parameters: 1,472,386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 (20.6s)\n",
      "  Train - Loss: 0.6694, Acc: 0.6123\n",
      "  Val   - Loss: 0.6438, Acc: 0.6350, AUC: 0.7152, AUPR: 0.5415\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 (19.7s)\n",
      "  Train - Loss: 0.6457, Acc: 0.6145\n",
      "  Val   - Loss: 0.6005, Acc: 0.6407, AUC: 0.7550, AUPR: 0.5732\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 (20.4s)\n",
      "  Train - Loss: 0.5848, Acc: 0.6620\n",
      "  Val   - Loss: 0.5289, Acc: 0.7250, AUC: 0.7925, AUPR: 0.6412\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 (21.7s)\n",
      "  Train - Loss: 0.5378, Acc: 0.7224\n",
      "  Val   - Loss: 0.5119, Acc: 0.7479, AUC: 0.8194, AUPR: 0.7043\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 (21.5s)\n",
      "  Train - Loss: 0.5174, Acc: 0.7413\n",
      "  Val   - Loss: 0.4935, Acc: 0.7511, AUC: 0.8311, AUPR: 0.7313\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 (20.4s)\n",
      "  Train - Loss: 0.4986, Acc: 0.7544\n",
      "  Val   - Loss: 0.4748, Acc: 0.7677, AUC: 0.8475, AUPR: 0.7595\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 (13.8s)\n",
      "  Train - Loss: 0.4831, Acc: 0.7592\n",
      "  Val   - Loss: 0.4572, Acc: 0.7817, AUC: 0.8590, AUPR: 0.7803\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 (14.2s)\n",
      "  Train - Loss: 0.4709, Acc: 0.7662\n",
      "  Val   - Loss: 0.4441, Acc: 0.7869, AUC: 0.8673, AUPR: 0.7925\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 (14.2s)\n",
      "  Train - Loss: 0.4612, Acc: 0.7720\n",
      "  Val   - Loss: 0.4340, Acc: 0.7932, AUC: 0.8726, AUPR: 0.8019\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 (14.1s)\n",
      "  Train - Loss: 0.4525, Acc: 0.7742\n",
      "  Val   - Loss: 0.4315, Acc: 0.7971, AUC: 0.8745, AUPR: 0.8045\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 (10.8s)\n",
      "  Train - Loss: 0.4522, Acc: 0.7828\n",
      "  Val   - Loss: 0.4264, Acc: 0.7971, AUC: 0.8767, AUPR: 0.8080\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 (10.2s)\n",
      "  Train - Loss: 0.4468, Acc: 0.7808\n",
      "  Val   - Loss: 0.4262, Acc: 0.7964, AUC: 0.8797, AUPR: 0.8132\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 (10.9s)\n",
      "  Train - Loss: 0.4476, Acc: 0.7865\n",
      "  Val   - Loss: 0.4228, Acc: 0.7977, AUC: 0.8778, AUPR: 0.8106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 (10.9s)\n",
      "  Train - Loss: 0.4443, Acc: 0.7859\n",
      "  Val   - Loss: 0.4189, Acc: 0.7983, AUC: 0.8796, AUPR: 0.8137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 (11.3s)\n",
      "  Train - Loss: 0.4426, Acc: 0.7891\n",
      "  Val   - Loss: 0.4206, Acc: 0.7958, AUC: 0.8772, AUPR: 0.8110\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 (12.5s)\n",
      "  Train - Loss: 0.4375, Acc: 0.7875\n",
      "  Val   - Loss: 0.4168, Acc: 0.8028, AUC: 0.8806, AUPR: 0.8154\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 (13.3s)\n",
      "  Train - Loss: 0.4354, Acc: 0.7852\n",
      "  Val   - Loss: 0.4170, Acc: 0.8015, AUC: 0.8813, AUPR: 0.8164\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 (10.9s)\n",
      "  Train - Loss: 0.4343, Acc: 0.7887\n",
      "  Val   - Loss: 0.4147, Acc: 0.8034, AUC: 0.8822, AUPR: 0.8183\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 (10.3s)\n",
      "  Train - Loss: 0.4312, Acc: 0.7894\n",
      "  Val   - Loss: 0.4142, Acc: 0.8034, AUC: 0.8825, AUPR: 0.8194\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 (11.1s)\n",
      "  Train - Loss: 0.4326, Acc: 0.7935\n",
      "  Val   - Loss: 0.4131, Acc: 0.8047, AUC: 0.8825, AUPR: 0.8196\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training Transformer\n",
      "============================================================\n",
      "\n",
      "Model parameters: 810,114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 (21.5s)\n",
      "  Train - Loss: 0.6719, Acc: 0.5846\n",
      "  Val   - Loss: 0.6350, Acc: 0.6382, AUC: 0.6573, AUPR: 0.5050\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 (20.4s)\n",
      "  Train - Loss: 0.6462, Acc: 0.6247\n",
      "  Val   - Loss: 0.6043, Acc: 0.6541, AUC: 0.7022, AUPR: 0.5504\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 (20.2s)\n",
      "  Train - Loss: 0.6047, Acc: 0.6611\n",
      "  Val   - Loss: 0.5556, Acc: 0.7090, AUC: 0.7633, AUPR: 0.6187\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 (20.0s)\n",
      "  Train - Loss: 0.5575, Acc: 0.7099\n",
      "  Val   - Loss: 0.5149, Acc: 0.7396, AUC: 0.8099, AUPR: 0.6740\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 (22.4s)\n",
      "  Train - Loss: 0.5174, Acc: 0.7409\n",
      "  Val   - Loss: 0.4787, Acc: 0.7620, AUC: 0.8422, AUPR: 0.7276\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 (27.0s)\n",
      "  Train - Loss: 0.4914, Acc: 0.7573\n",
      "  Val   - Loss: 0.4619, Acc: 0.7811, AUC: 0.8561, AUPR: 0.7470\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 (21.7s)\n",
      "  Train - Loss: 0.4811, Acc: 0.7678\n",
      "  Val   - Loss: 0.4551, Acc: 0.7862, AUC: 0.8600, AUPR: 0.7629\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 (32.3s)\n",
      "  Train - Loss: 0.4812, Acc: 0.7614\n",
      "  Val   - Loss: 0.4586, Acc: 0.7779, AUC: 0.8600, AUPR: 0.7652\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 (26.3s)\n",
      "  Train - Loss: 0.4665, Acc: 0.7758\n",
      "  Val   - Loss: 0.4501, Acc: 0.7875, AUC: 0.8628, AUPR: 0.7726\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 (28.1s)\n",
      "  Train - Loss: 0.4662, Acc: 0.7729\n",
      "  Val   - Loss: 0.4537, Acc: 0.7913, AUC: 0.8629, AUPR: 0.7769\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 (27.8s)\n",
      "  Train - Loss: 0.4595, Acc: 0.7764\n",
      "  Val   - Loss: 0.4541, Acc: 0.7881, AUC: 0.8676, AUPR: 0.7798\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 (26.6s)\n",
      "  Train - Loss: 0.4638, Acc: 0.7776\n",
      "  Val   - Loss: 0.4402, Acc: 0.7977, AUC: 0.8684, AUPR: 0.7838\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 (35.6s)\n",
      "  Train - Loss: 0.4572, Acc: 0.7784\n",
      "  Val   - Loss: 0.4378, Acc: 0.7983, AUC: 0.8714, AUPR: 0.7858\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 (38.6s)\n",
      "  Train - Loss: 0.4555, Acc: 0.7844\n",
      "  Val   - Loss: 0.4418, Acc: 0.7958, AUC: 0.8693, AUPR: 0.7855\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 (38.0s)\n",
      "  Train - Loss: 0.4509, Acc: 0.7836\n",
      "  Val   - Loss: 0.4417, Acc: 0.7945, AUC: 0.8683, AUPR: 0.7862\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 (39.6s)\n",
      "  Train - Loss: 0.4510, Acc: 0.7847\n",
      "  Val   - Loss: 0.4309, Acc: 0.8041, AUC: 0.8733, AUPR: 0.7913\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 (38.4s)\n",
      "  Train - Loss: 0.4496, Acc: 0.7865\n",
      "  Val   - Loss: 0.4319, Acc: 0.7990, AUC: 0.8733, AUPR: 0.7920\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 (34.3s)\n",
      "  Train - Loss: 0.4397, Acc: 0.7956\n",
      "  Val   - Loss: 0.4268, Acc: 0.8034, AUC: 0.8754, AUPR: 0.7955\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 (24.8s)\n",
      "  Train - Loss: 0.4444, Acc: 0.7892\n",
      "  Val   - Loss: 0.4297, Acc: 0.8009, AUC: 0.8768, AUPR: 0.7965\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 (26.5s)\n",
      "  Train - Loss: 0.4436, Acc: 0.7924\n",
      "  Val   - Loss: 0.4295, Acc: 0.8022, AUC: 0.8726, AUPR: 0.7938\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training CNN-LSTM\n",
      "============================================================\n",
      "\n",
      "Model parameters: 360,642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 (10.1s)\n",
      "  Train - Loss: 0.6798, Acc: 0.6028\n",
      "  Val   - Loss: 0.6581, Acc: 0.6375, AUC: 0.7001, AUPR: 0.5239\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 (10.4s)\n",
      "  Train - Loss: 0.6479, Acc: 0.6145\n",
      "  Val   - Loss: 0.6098, Acc: 0.6388, AUC: 0.7308, AUPR: 0.5492\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 (9.7s)\n",
      "  Train - Loss: 0.5907, Acc: 0.6303\n",
      "  Val   - Loss: 0.5400, Acc: 0.7141, AUC: 0.7422, AUPR: 0.5687\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 (9.3s)\n",
      "  Train - Loss: 0.5496, Acc: 0.7091\n",
      "  Val   - Loss: 0.5250, Acc: 0.7307, AUC: 0.7938, AUPR: 0.6487\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 (8.9s)\n",
      "  Train - Loss: 0.5378, Acc: 0.7112\n",
      "  Val   - Loss: 0.5172, Acc: 0.7307, AUC: 0.8120, AUPR: 0.6885\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 (8.9s)\n",
      "  Train - Loss: 0.5302, Acc: 0.7195\n",
      "  Val   - Loss: 0.5082, Acc: 0.7415, AUC: 0.8193, AUPR: 0.7174\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 (9.1s)\n",
      "  Train - Loss: 0.5154, Acc: 0.7310\n",
      "  Val   - Loss: 0.4944, Acc: 0.7498, AUC: 0.8262, AUPR: 0.7397\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 (10.7s)\n",
      "  Train - Loss: 0.5012, Acc: 0.7460\n",
      "  Val   - Loss: 0.4729, Acc: 0.7849, AUC: 0.8520, AUPR: 0.7813\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 (10.2s)\n",
      "  Train - Loss: 0.4867, Acc: 0.7592\n",
      "  Val   - Loss: 0.4650, Acc: 0.7875, AUC: 0.8569, AUPR: 0.7861\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 (10.0s)\n",
      "  Train - Loss: 0.4819, Acc: 0.7608\n",
      "  Val   - Loss: 0.4583, Acc: 0.7869, AUC: 0.8599, AUPR: 0.7906\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 (9.5s)\n",
      "  Train - Loss: 0.4758, Acc: 0.7643\n",
      "  Val   - Loss: 0.4510, Acc: 0.7900, AUC: 0.8612, AUPR: 0.7913\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 (9.5s)\n",
      "  Train - Loss: 0.4673, Acc: 0.7737\n",
      "  Val   - Loss: 0.4443, Acc: 0.7824, AUC: 0.8641, AUPR: 0.7937\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 (16.2s)\n",
      "  Train - Loss: 0.4584, Acc: 0.7742\n",
      "  Val   - Loss: 0.4386, Acc: 0.7932, AUC: 0.8675, AUPR: 0.7976\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 (12.7s)\n",
      "  Train - Loss: 0.4587, Acc: 0.7771\n",
      "  Val   - Loss: 0.4346, Acc: 0.7932, AUC: 0.8690, AUPR: 0.7987\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 (11.4s)\n",
      "  Train - Loss: 0.4543, Acc: 0.7747\n",
      "  Val   - Loss: 0.4303, Acc: 0.7900, AUC: 0.8719, AUPR: 0.8022\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 (27.5s)\n",
      "  Train - Loss: 0.4526, Acc: 0.7796\n",
      "  Val   - Loss: 0.4309, Acc: 0.7894, AUC: 0.8720, AUPR: 0.8028\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 (28.8s)\n",
      "  Train - Loss: 0.4468, Acc: 0.7803\n",
      "  Val   - Loss: 0.4249, Acc: 0.7875, AUC: 0.8742, AUPR: 0.8046\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 (28.6s)\n",
      "  Train - Loss: 0.4465, Acc: 0.7824\n",
      "  Val   - Loss: 0.4223, Acc: 0.7926, AUC: 0.8754, AUPR: 0.8065\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 (12.4s)\n",
      "  Train - Loss: 0.4403, Acc: 0.7835\n",
      "  Val   - Loss: 0.4196, Acc: 0.7951, AUC: 0.8766, AUPR: 0.8088\n",
      "  [*] Best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 (11.4s)\n",
      "  Train - Loss: 0.4395, Acc: 0.7852\n",
      "  Val   - Loss: 0.4159, Acc: 0.7945, AUC: 0.8780, AUPR: 0.8110\n",
      "  [*] Best model saved!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "COMPARATIVE RESULTS\n",
      "================================================================================\n",
      "Model           AUC      AUPR     Acc      Prec     Recall   Params     Time(s)   \n",
      "--------------------------------------------------------------------------------\n",
      "CNN             0.8919   0.8382   0.8175   0.7757   0.7143   14,594,498 329.5     \n",
      "BiLSTM          0.8825   0.8194   0.8034   0.7205   0.7676   1,472,386  292.8     \n",
      "Transformer     0.8768   0.7965   0.8009   0.7663   0.6661   810,114    570.0     \n",
      "CNN-LSTM        0.8780   0.8110   0.7945   0.7342   0.6988   360,642    265.2     \n",
      "\n",
      "Results saved to 'model_comparison_results.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, average_precision_score,\n",
    "                             precision_score, recall_score, roc_curve, precision_recall_curve)\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "class ImprovedDataset(Dataset):\n",
    "    \"\"\"Dataset class for immunogenicity prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, aaindex_path=\"./data/aaindex1_pca.csv\"):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.aaindex = pd.read_csv(aaindex_path)\n",
    "        self.amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        pseudosequence = row['pseudosequence']\n",
    "        peptide = row['Peptide']\n",
    "        label = row['Label']\n",
    "        tap = row['tap_prediction_score']\n",
    "        rank = row['%Rank_EL']\n",
    "        \n",
    "        pseudo_onehot = self._onehot_encoding(pseudosequence, 34)\n",
    "        peptide_onehot = self._onehot_encoding(peptide, 11)\n",
    "        pseudo_aa = self._get_AA_features(pseudosequence, 34)\n",
    "        peptide_aa = self._get_AA_features(peptide, 11)\n",
    "        \n",
    "        pseudo_features = torch.cat([pseudo_onehot, pseudo_aa], dim=1)  # [34, 42]\n",
    "        peptide_features = torch.cat([peptide_onehot, peptide_aa], dim=1)  # [11, 42]\n",
    "        \n",
    "        global_features = torch.tensor([tap, rank], dtype=torch.float32)\n",
    "        \n",
    "        return (pseudo_features.float(), \n",
    "                peptide_features.float(), \n",
    "                global_features, \n",
    "                torch.tensor(label, dtype=torch.long))\n",
    "    \n",
    "    def _onehot_encoding(self, sequence, maxlen):\n",
    "        sequence = sequence.upper()[:maxlen]\n",
    "        enc_seq = torch.zeros((maxlen, 20), dtype=torch.float32)\n",
    "        \n",
    "        for i, aa in enumerate(sequence):\n",
    "            if aa in self.amino_acids:\n",
    "                enc_seq[i, self.amino_acids.index(aa)] = 1\n",
    "        \n",
    "        return enc_seq\n",
    "    \n",
    "    def _get_AA_features(self, sequence, maxlen):\n",
    "        sequence = sequence.ljust(maxlen, 'X')[:maxlen]\n",
    "        \n",
    "        all_node_feats = []\n",
    "        for index, aa in enumerate(sequence):\n",
    "            node_feats = self.aaindex[aa].to_list()\n",
    "            anchar = [0, maxlen]\n",
    "            seq_onehot = [0, 0]\n",
    "            seq_onehot[sum([index >= i for i in anchar]) - 1] = 1\n",
    "            node_feats.extend(seq_onehot)\n",
    "            all_node_feats.append(node_feats)\n",
    "        \n",
    "        return torch.tensor(all_node_feats, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# ==================== Model 1: CNN (Original) ====================\n",
    "class ImprovedCNN(nn.Module):\n",
    "    \"\"\"CNN-based model for local motif detection\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ImprovedCNN, self).__init__()\n",
    "        \n",
    "        self.pseudo_branch = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=2, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1), stride=2)\n",
    "        )\n",
    "        \n",
    "        self.peptide_branch = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=2, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1), stride=2)\n",
    "        )\n",
    "        \n",
    "        self.conv_output_dim = self._get_conv_output()\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.conv_output_dim + 2, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "    \n",
    "    def _get_conv_output(self):\n",
    "        with torch.no_grad():\n",
    "            x1 = torch.zeros(1, 1, 34, 42)\n",
    "            x2 = torch.zeros(1, 1, 11, 42)\n",
    "            x1 = self.pseudo_branch(x1)\n",
    "            x2 = self.peptide_branch(x2)\n",
    "            x1_flat = x1.view(1, -1).size(1)\n",
    "            x2_flat = x2.view(1, -1).size(1)\n",
    "            return x1_flat + x2_flat\n",
    "    \n",
    "    def forward(self, pseudo, peptide, global_feat):\n",
    "        x1 = pseudo.unsqueeze(1)\n",
    "        x2 = peptide.unsqueeze(1)\n",
    "        \n",
    "        x1 = self.pseudo_branch(x1)\n",
    "        x2 = self.peptide_branch(x2)\n",
    "        \n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "        \n",
    "        x = torch.cat([x1, x2, global_feat], dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ==================== Model 2: BiLSTM ====================\n",
    "class BiLSTMModel(nn.Module):\n",
    "    \"\"\"BiLSTM-based model for sequential pattern learning\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim=128, num_layers=2):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        \n",
    "        # LSTM for pseudo sequence\n",
    "        self.pseudo_lstm = nn.LSTM(\n",
    "            input_size=42,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        # LSTM for peptide sequence\n",
    "        self.peptide_lstm = nn.LSTM(\n",
    "            input_size=42,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        lstm_output_dim = hidden_dim * 2 * 2  # bidirectional * 2 sequences\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lstm_output_dim + 2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, pseudo, peptide, global_feat):\n",
    "        # Process pseudo sequence\n",
    "        pseudo_out, (pseudo_h, _) = self.pseudo_lstm(pseudo)\n",
    "        # Concatenate forward and backward hidden states from last layer\n",
    "        pseudo_feat = torch.cat([pseudo_h[-2], pseudo_h[-1]], dim=1)\n",
    "        \n",
    "        # Process peptide sequence\n",
    "        peptide_out, (peptide_h, _) = self.peptide_lstm(peptide)\n",
    "        peptide_feat = torch.cat([peptide_h[-2], peptide_h[-1]], dim=1)\n",
    "        \n",
    "        # Concatenate all features\n",
    "        x = torch.cat([pseudo_feat, peptide_feat, global_feat], dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ==================== Model 3: Transformer ====================\n",
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"Transformer-based model with self-attention mechanism\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model=128, nhead=8, num_layers=3):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        # Input projection\n",
    "        self.pseudo_proj = nn.Linear(42, d_model)\n",
    "        self.peptide_proj = nn.Linear(42, d_model)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pseudo_pos = nn.Parameter(torch.randn(1, 34, d_model))\n",
    "        self.peptide_pos = nn.Parameter(torch.randn(1, 11, d_model))\n",
    "        \n",
    "        # Transformer encoders\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=512,\n",
    "            dropout=0.3,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model * 2 + 2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, pseudo, peptide, global_feat):\n",
    "        # Project and add positional encoding\n",
    "        pseudo_x = self.pseudo_proj(pseudo) + self.pseudo_pos\n",
    "        peptide_x = self.peptide_proj(peptide) + self.peptide_pos\n",
    "        \n",
    "        # Apply transformer\n",
    "        pseudo_out = self.transformer(pseudo_x)\n",
    "        peptide_out = self.transformer(peptide_x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        pseudo_feat = pseudo_out.mean(dim=1)\n",
    "        peptide_feat = peptide_out.mean(dim=1)\n",
    "        \n",
    "        # Concatenate and classify\n",
    "        x = torch.cat([pseudo_feat, peptide_feat, global_feat], dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ==================== Model 4: Hybrid CNN-LSTM ====================\n",
    "class HybridCNNLSTM(nn.Module):\n",
    "    \"\"\"Hybrid model combining CNN for local features and LSTM for sequential patterns\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HybridCNNLSTM, self).__init__()\n",
    "        \n",
    "        # CNN layers for local motif extraction\n",
    "        self.pseudo_conv = nn.Sequential(\n",
    "            nn.Conv1d(42, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.peptide_conv = nn.Sequential(\n",
    "            nn.Conv1d(42, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # LSTM layers for sequential patterns\n",
    "        self.pseudo_lstm = nn.LSTM(64, 64, batch_first=True, bidirectional=True)\n",
    "        self.peptide_lstm = nn.LSTM(64, 64, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 4 + 2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, pseudo, peptide, global_feat):\n",
    "        # CNN processing (transpose for Conv1d: batch, channels, length)\n",
    "        pseudo_x = self.pseudo_conv(pseudo.transpose(1, 2))\n",
    "        peptide_x = self.peptide_conv(peptide.transpose(1, 2))\n",
    "        \n",
    "        # Transpose back for LSTM\n",
    "        pseudo_x = pseudo_x.transpose(1, 2)\n",
    "        peptide_x = peptide_x.transpose(1, 2)\n",
    "        \n",
    "        # LSTM processing\n",
    "        _, (pseudo_h, _) = self.pseudo_lstm(pseudo_x)\n",
    "        _, (peptide_h, _) = self.peptide_lstm(peptide_x)\n",
    "        \n",
    "        # Concatenate bidirectional hidden states\n",
    "        pseudo_feat = torch.cat([pseudo_h[0], pseudo_h[1]], dim=1)\n",
    "        peptide_feat = torch.cat([peptide_h[0], peptide_h[1]], dim=1)\n",
    "        \n",
    "        # Concatenate all features\n",
    "        x = torch.cat([pseudo_feat, peptide_feat, global_feat], dim=1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ==================== Training and Evaluation Functions ====================\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for pseudo, peptide, global_feat, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        pseudo = pseudo.to(device)\n",
    "        peptide = peptide.to(device)\n",
    "        global_feat = global_feat.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(pseudo, peptide, global_feat)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate_model(model, criterion, dataloader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for pseudo, peptide, global_feat, labels in tqdm(dataloader, desc=\"Evaluation\", leave=False):\n",
    "            pseudo = pseudo.to(device)\n",
    "            peptide = peptide.to(device)\n",
    "            global_feat = global_feat.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(pseudo, peptide, global_feat)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    \n",
    "    precision = precision_score(all_labels, all_predictions, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions, zero_division=0)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    aupr = average_precision_score(all_labels, all_probs)\n",
    "    acc = accuracy_score(all_labels, all_predictions)\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'auc': auc,\n",
    "        'aupr': aupr,\n",
    "        'acc': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def train_and_evaluate(model_class, model_name, train_loader, val_loader, \n",
    "                       num_epochs=30, lr=0.0001, device=device):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    model = model_class().to(device)\n",
    "    print(f\"Model parameters: {count_parameters(model):,}\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
    "    \n",
    "    best_auc = 0\n",
    "    best_metrics = None\n",
    "    training_time = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_metrics = evaluate_model(model, criterion, val_loader, device)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        training_time += epoch_time\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} ({epoch_time:.1f}s)\")\n",
    "        print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "        print(f\"  Val   - Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['acc']:.4f}, \"\n",
    "              f\"AUC: {val_metrics['auc']:.4f}, AUPR: {val_metrics['aupr']:.4f}\")\n",
    "        \n",
    "        if val_metrics['auc'] > best_auc:\n",
    "            best_auc = val_metrics['auc']\n",
    "            best_metrics = val_metrics.copy()\n",
    "            torch.save(model.state_dict(), f'best_{model_name}.pth')\n",
    "            print(f\"  [*] Best model saved!\")\n",
    "        print()\n",
    "    \n",
    "    best_metrics['training_time'] = training_time\n",
    "    best_metrics['parameters'] = count_parameters(model)\n",
    "    \n",
    "    return model, best_metrics\n",
    "\n",
    "\n",
    "# ==================== Main Comparison ====================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading data...\")\n",
    "    data = pd.read_csv(\"data/output_binding_tap.csv\")\n",
    "    train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_dataset = ImprovedDataset(train_data)\n",
    "    val_dataset = ImprovedDataset(val_data)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    print(f\"Val samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Define models to compare\n",
    "    models = [\n",
    "        (ImprovedCNN, \"CNN\"),\n",
    "        (BiLSTMModel, \"BiLSTM\"),\n",
    "        (TransformerModel, \"Transformer\"),\n",
    "        (HybridCNNLSTM, \"CNN-LSTM\")\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Train each model\n",
    "    for model_class, model_name in models:\n",
    "        try:\n",
    "            _, metrics = train_and_evaluate(\n",
    "                model_class, \n",
    "                model_name,\n",
    "                train_loader, \n",
    "                val_loader,\n",
    "                num_epochs=20,  # 10\n",
    "                lr=0.0001\n",
    "            )\n",
    "            results[model_name] = metrics\n",
    "        except Exception as e:\n",
    "            print(f\"Error training {model_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Print comparison table\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPARATIVE RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Model':<15} {'AUC':<8} {'AUPR':<8} {'Acc':<8} {'Prec':<8} {'Recall':<8} {'Params':<10} {'Time(s)':<10}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for model_name, metrics in results.items():\n",
    "        print(f\"{model_name:<15} \"\n",
    "              f\"{metrics['auc']:<8.4f} \"\n",
    "              f\"{metrics['aupr']:<8.4f} \"\n",
    "              f\"{metrics['acc']:<8.4f} \"\n",
    "              f\"{metrics['precision']:<8.4f} \"\n",
    "              f\"{metrics['recall']:<8.4f} \"\n",
    "              f\"{metrics['parameters']:<10,} \"\n",
    "              f\"{metrics['training_time']:<10.1f}\")\n",
    "    \n",
    "    # Save results\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    results_df.to_csv('model_comparison_results.csv')\n",
    "    print(\"\\nResults saved to 'model_comparison_results.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
